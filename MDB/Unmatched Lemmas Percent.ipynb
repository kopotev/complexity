{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7vPwpyP9ay/tqmEHdbBw0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakhranev/MDB/blob/main/Unmatched%20Lemmas%20Percent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "6TsTiyJO6Ofv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eakKs345iqe",
        "outputId": "1886ec93-0e6e-4f9f-c9a2-7f5f6086b323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level A1:\n",
            "  Matches: 721\n",
            "  Unique in SMARTool: 3\n",
            "  Unique in LM: 273\n",
            "\n",
            "Level A2:\n",
            "  Matches: 497\n",
            "  Unique in SMARTool: 536\n",
            "  Unique in LM: 77\n",
            "\n",
            "Level B1:\n",
            "  Matches: 927\n",
            "  Unique in SMARTool: 150\n",
            "  Unique in LM: 12\n",
            "\n",
            "Level B2:\n",
            "  Matches: 3175\n",
            "  Unique in SMARTool: 2\n",
            "  Unique in LM: 41\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load SMARTool dictionaries\n",
        "df_A1 = pd.read_csv('A1.csv', sep=';')\n",
        "A1 = df_A1[:754]\n",
        "df_A2 = pd.read_csv('A2.csv', sep=';')\n",
        "A2 = df_A2[:1048]\n",
        "df_B1 = pd.read_csv('B1.csv', sep=';')\n",
        "B1 = df_B1[:1081]\n",
        "df_B2 = pd.read_csv('B2.csv', sep=';')\n",
        "B2 = df_B2[:3331]\n",
        "\n",
        "slovar_smartool_A1 = A1['Lemma'].str.lower().tolist()\n",
        "slovar_smartool_A2 = A2['Unnamed: 0'].str.lower().tolist()\n",
        "slovar_smartool_B1 = B1['Lemma'].str.lower().tolist()\n",
        "slovar_smartool_B2 = B2['Lemma'].str.lower().tolist()\n",
        "\n",
        "# Load LM dictionaries\n",
        "df_nv1 = pd.read_csv('new_vocab_a1.csv', sep=';')\n",
        "df_nv1 = df_nv1[df_nv1['а'].str.len() >= 2]\n",
        "nv1 = df_nv1['а'].str.lower().tolist()\n",
        "\n",
        "df_nv2 = pd.read_csv('new_vocab_a2.csv', sep=';')\n",
        "df_nv2 = df_nv2[df_nv2['а'].str.len() >= 2]\n",
        "nv2 = df_nv2['а'].str.lower().tolist()\n",
        "\n",
        "df_nv3 = pd.read_csv('new_vocab_b1.csv', sep=';')\n",
        "df_nv3 = df_nv3[df_nv3['а'].str.len() >= 2]\n",
        "nv3 = df_nv3['а'].str.lower().tolist()\n",
        "\n",
        "df_nv4 = pd.read_csv('new_vocab_b2.csv', sep=';')\n",
        "df_nv4 = df_nv4[df_nv4['а'].str.len() >= 2]\n",
        "nv4 = df_nv4['а'].str.lower().tolist()\n",
        "\n",
        "slovar_LM_A1 = nv1\n",
        "slovar_LM_A2 = list(set(nv2) - set(nv1))\n",
        "slovar_LM_B1 = list(set(nv3) - set(nv2))\n",
        "slovar_LM_B2 = list(set(nv4) - set(nv3))\n",
        "\n",
        "# Function to compare and get the number of matches and unique lemmas\n",
        "def compare_lemmas(slovar1, slovar2):\n",
        "    set1 = set(slovar1)\n",
        "    set2 = set(slovar2)\n",
        "    matches = len(set1.intersection(set2))\n",
        "    unique_slovar1 = len(set1 - set2)\n",
        "    unique_slovar2 = len(set2 - set1)\n",
        "    return matches, unique_slovar1, unique_slovar2\n",
        "\n",
        "# Compare each level\n",
        "levels = ['A1', 'A2', 'B1', 'B2']\n",
        "for level in levels:\n",
        "    slovar_smartool = globals()[f'slovar_smartool_{level}']\n",
        "    slovar_LM = globals()[f'slovar_LM_{level}']\n",
        "    matches, unique_smartool, unique_LM = compare_lemmas(slovar_smartool, slovar_LM)\n",
        "    print(f\"Level {level}:\")\n",
        "    print(f\"  Matches: {matches}\")\n",
        "    print(f\"  Unique in SMARTool: {unique_smartool}\")\n",
        "    print(f\"  Unique in LM: {unique_LM}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import string\n",
        "from pymystem3 import Mystem\n",
        "\n",
        "# Initialize Mystem\n",
        "mystem = Mystem()\n",
        "\n",
        "# Load dictionaries for SMARTool\n",
        "df_A1 = pd.read_csv('A1.csv', sep=';')\n",
        "df_A1.index = pd.RangeIndex(start=1, stop=len(df_A1) + 1)\n",
        "slovar1 = df_A1['Lemma'].str.lower().tolist()\n",
        "\n",
        "df_A2 = pd.read_csv('A2.csv', sep=';')\n",
        "df_A2.index = pd.RangeIndex(start=1, stop=len(df_A2) + 1)\n",
        "slovar2 = df_A2['Unnamed: 0'].str.lower().tolist()\n",
        "\n",
        "df_B1 = pd.read_csv('B1.csv', sep=';')\n",
        "df_B1.index = pd.RangeIndex(start=1, stop=len(df_B1) + 1)\n",
        "slovar3 = df_B1['Lemma'].str.lower().tolist()\n",
        "\n",
        "df_B2 = pd.read_csv('B2.csv', sep=';')\n",
        "df_B2.index = pd.RangeIndex(start=1, stop=len(df_B2) + 1)\n",
        "slovar4 = df_B2['Lemma'].str.lower().tolist()\n",
        "\n",
        "# Load dictionaries for LM (new vocabularies)\n",
        "df_nv1 = pd.read_csv('new_vocab_a1.csv', sep=';')\n",
        "df_nv1.index = pd.RangeIndex(start=1, stop=len(df_nv1) + 1)\n",
        "nv1 = df_nv1[df_nv1['а'].str.len() >= 2]['а'].str.lower().tolist()\n",
        "\n",
        "df_nv2 = pd.read_csv('new_vocab_a2.csv', sep=';')\n",
        "df_nv2.index = pd.RangeIndex(start=1, stop=len(df_nv2) + 1)\n",
        "nv2 = df_nv2[df_nv2['а'].str.len() >= 2]['а'].str.lower().tolist()\n",
        "\n",
        "df_nv3 = pd.read_csv('new_vocab_b1.csv', sep=';')\n",
        "df_nv3.index = pd.RangeIndex(start=1, stop=len(df_nv3) + 1)\n",
        "nv3 = df_nv3[df_nv3['а'].str.len() >= 2]['а'].str.lower().tolist()\n",
        "\n",
        "df_nv4 = pd.read_csv('new_vocab_b2.csv', sep=';')\n",
        "df_nv4.index = pd.RangeIndex(start=1, stop=len(df_nv4) + 1)\n",
        "nv4 = df_nv4[df_nv4['а'].str.len() >= 2]['а'].str.lower().tolist()\n",
        "\n",
        "# Clean words from quotes in new vocabularies\n",
        "slovar_nv1 = [word.strip(\"'\") for word in nv1]\n",
        "\n",
        "# Чистка словаря nv2 от слов, которые уже есть в словаре nv1\n",
        "slovar_nv2 = [word.strip(\"'\") for word in nv2 if word.strip(\"'\") not in slovar_nv1]\n",
        "\n",
        "# Чистка словаря nv3 от слов, которые уже есть в словарях nv1 и nv2\n",
        "slovar_nv3 = [word.strip(\"'\") for word in nv3 if word.strip(\"'\") not in slovar_nv1 and word.strip(\"'\") not in slovar_nv2]\n",
        "\n",
        "# Чистка словаря nv4 от слов, которые уже есть в словарях nv1, nv2 и nv3\n",
        "slovar_nv4 = [word.strip(\"'\") for word in nv4 if word.strip(\"'\") not in slovar_nv1 and word.strip(\"'\") not in slovar_nv2 and word.strip(\"'\") not in slovar_nv3]\n",
        "\n",
        "# Folder path with students' texts\n",
        "students_path = r\"/content/Students_texts\"\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    lemmatized_words = []\n",
        "    for word in words:\n",
        "        word = word.strip(string.punctuation)\n",
        "        if word:\n",
        "            lemmatized_words.append(word.lower())\n",
        "    return lemmatized_words\n",
        "\n",
        "def process_folder(folder_path, slovar1, slovar2, slovar3, slovar4):\n",
        "    total_unmatched_percentage = 0\n",
        "    total_unmatched_tokens = 0\n",
        "    total_files = 0\n",
        "\n",
        "    for file_path in glob.glob(folder_path + \"/*.txt\"):\n",
        "        with open(file_path, \"r\", encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "            lemmas = lemmatize_text(text)\n",
        "            unique_lemmas = set(lemmas)\n",
        "\n",
        "            matched_slovar1 = len(unique_lemmas.intersection(slovar1))\n",
        "            matched_slovar2 = len(unique_lemmas.intersection(slovar2))\n",
        "            matched_slovar3 = len(unique_lemmas.intersection(slovar3))\n",
        "            matched_slovar4 = len(unique_lemmas.intersection(slovar4))\n",
        "\n",
        "            total_matched = matched_slovar1 + matched_slovar2 + matched_slovar3 + matched_slovar4\n",
        "            total_unmatched = len(unique_lemmas) - total_matched\n",
        "\n",
        "            # Ensure that the total number of unmatched lemmas is not negative\n",
        "            total_unmatched = max(0, total_unmatched)\n",
        "\n",
        "            # Calculate the percentage of unmatched lemmas\n",
        "            unmatched_percentage = (total_unmatched / len(unique_lemmas)) * 100 if len(unique_lemmas) > 0 else 0\n",
        "\n",
        "            total_unmatched_percentage += unmatched_percentage\n",
        "            total_unmatched_tokens += total_unmatched\n",
        "            total_files += 1\n",
        "\n",
        "    avg_unmatched_percentage = total_unmatched_percentage / total_files if total_files > 0 else 0\n",
        "    avg_unmatched_tokens = total_unmatched_tokens / total_files if total_files > 0 else 0\n",
        "    return avg_unmatched_percentage, avg_unmatched_tokens\n",
        "\n",
        "# Process folders A1, A2, B1, B2 with SMARTool dictionaries\n",
        "print(\"Processing with SMARTool dictionaries:\")\n",
        "folders = [\"A1\", \"A2\", \"B1\", \"B2\"]\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(students_path, folder)\n",
        "    avg_unmatched_percentage, avg_unmatched_tokens = process_folder(folder_path, slovar1, slovar2, slovar3, slovar4)\n",
        "    print(f\"Average unmatched lemmas percentage for folder {folder} (SMARTool): {avg_unmatched_percentage:.2f}%\")\n",
        "    print(f\"Average unmatched lemmas count for folder {folder} (SMARTool): {avg_unmatched_tokens:.2f}\")\n",
        "\n",
        "# Process folders A1, A2, B1, B2 with new vocabularies\n",
        "print(\"\\nProcessing with new vocabularies:\")\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(students_path, folder)\n",
        "    avg_unmatched_percentage, avg_unmatched_tokens = process_folder(folder_path, slovar_nv1, slovar_nv2, slovar_nv3, slovar_nv4)\n",
        "    print(f\"Average unmatched lemmas percentage for folder {folder} (New Vocabularies): {avg_unmatched_percentage:.2f}%\")\n",
        "    print(f\"Average unmatched lemmas count for folder {folder} (New Vocabularies): {avg_unmatched_tokens:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyvCQMzN_zEl",
        "outputId": "11f6117d-f75e-4efb-c730-c179f95f617a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing with SMARTool dictionaries:\n",
            "Average unmatched lemmas percentage for folder A1 (SMARTool): 74.24%\n",
            "Average unmatched lemmas count for folder A1 (SMARTool): 29.40\n",
            "Average unmatched lemmas percentage for folder A2 (SMARTool): 75.48%\n",
            "Average unmatched lemmas count for folder A2 (SMARTool): 65.13\n",
            "Average unmatched lemmas percentage for folder B1 (SMARTool): 77.31%\n",
            "Average unmatched lemmas count for folder B1 (SMARTool): 95.61\n",
            "Average unmatched lemmas percentage for folder B2 (SMARTool): 78.23%\n",
            "Average unmatched lemmas count for folder B2 (SMARTool): 130.29\n",
            "\n",
            "Processing with new vocabularies:\n",
            "Average unmatched lemmas percentage for folder A1 (New Vocabularies): 59.50%\n",
            "Average unmatched lemmas count for folder A1 (New Vocabularies): 23.13\n",
            "Average unmatched lemmas percentage for folder A2 (New Vocabularies): 57.41%\n",
            "Average unmatched lemmas count for folder A2 (New Vocabularies): 50.16\n",
            "Average unmatched lemmas percentage for folder B1 (New Vocabularies): 60.95%\n",
            "Average unmatched lemmas count for folder B1 (New Vocabularies): 76.09\n",
            "Average unmatched lemmas percentage for folder B2 (New Vocabularies): 64.64%\n",
            "Average unmatched lemmas count for folder B2 (New Vocabularies): 108.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import string\n",
        "from pymystem3 import Mystem\n",
        "\n",
        "# Initialize Mystem\n",
        "mystem = Mystem()\n",
        "\n",
        "# Load frequency dictionary for each thousand words\n",
        "df = pd.read_csv('ru_m3.csv', sep=';')\n",
        "df.index = pd.RangeIndex(start=1, stop=len(df) + 1)\n",
        "df = df[['Lemma', 'CEFR']]\n",
        "mark1 = \"a1\"\n",
        "mark2 = \"a2\"\n",
        "mark3 = \"b1\"\n",
        "mark4 = \"b2\"\n",
        "mark5 = \"A1\"\n",
        "mark6 = \"A2\"\n",
        "mark7 = \"B1\"\n",
        "mark8 = \"B2\"\n",
        "dc1 = df.query('CEFR == @mark1 | CEFR == @mark5')\n",
        "dc2 = df.query('CEFR == @mark2 | CEFR == @mark6')\n",
        "dc3 = df.query('CEFR == @mark3 | CEFR == @mark7')\n",
        "dc4 = df.query('CEFR == @mark4 | CEFR == @mark8')\n",
        "\n",
        "l = []\n",
        "for word in dc1['Lemma']:\n",
        "    if word not in l:\n",
        "        l.append(word)\n",
        "slovar1 = l\n",
        "\n",
        "l = []\n",
        "for word in dc2['Lemma']:\n",
        "    if word not in l:\n",
        "        l.append(word)\n",
        "slovar2 = l\n",
        "\n",
        "l = []\n",
        "for word in dc3['Lemma']:\n",
        "    if word not in l:\n",
        "        l.append(word)\n",
        "slovar3 = l\n",
        "\n",
        "l = []\n",
        "for word in dc4['Lemma']:\n",
        "    if word not in l:\n",
        "        l.append(word)\n",
        "slovar4 = l\n",
        "\n",
        "df = pd.read_csv('lemmas_levels.csv', sep=',')\n",
        "df.index = pd.RangeIndex(start=1, stop=len(df) + 1)\n",
        "mark1 = \"1E\"\n",
        "mark2 = \"2I\"\n",
        "mark3 = \"3AU\"\n",
        "mark4 = \"4S\"\n",
        "ll1 = df.query('level == @mark1')\n",
        "ll2 = df.query('level == @mark2')\n",
        "ll3 = df.query('level == @mark3')\n",
        "ll4 = df.query('level == @mark4')\n",
        "\n",
        "slovar_nv1 = ll1['lemma'].str.strip('\\'').tolist()\n",
        "slovar_nv2 = ll2['lemma'].str.strip('\\'').tolist()\n",
        "slovar_nv3 = ll3['lemma'].str.strip('\\'').tolist()\n",
        "slovar_nv4 = ll4['lemma'].str.strip('\\'').tolist()\n",
        "\n",
        "# Folder path with students' texts\n",
        "students_path = r\"/content/Students_texts\"\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    lemmatized_words = []\n",
        "    for word in words:\n",
        "        word = word.strip(string.punctuation)\n",
        "        if word:\n",
        "            lemmatized_words.append(word.lower())\n",
        "    return lemmatized_words\n",
        "\n",
        "def process_folder(folder_path, slovar1, slovar2, slovar3, slovar4):\n",
        "    total_unmatched_percentage = 0\n",
        "    total_unmatched_tokens = 0\n",
        "    total_files = 0\n",
        "\n",
        "    for file_path in glob.glob(folder_path + \"/*.txt\"):\n",
        "        with open(file_path, \"r\", encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "            lemmas = lemmatize_text(text)\n",
        "            unique_lemmas = set(lemmas)\n",
        "\n",
        "            matched_slovar1 = len(unique_lemmas.intersection(slovar1))\n",
        "            matched_slovar2 = len(unique_lemmas.intersection(slovar2))\n",
        "            matched_slovar3 = len(unique_lemmas.intersection(slovar3))\n",
        "            matched_slovar4 = len(unique_lemmas.intersection(slovar4))\n",
        "\n",
        "            total_matched = matched_slovar1 + matched_slovar2 + matched_slovar3 + matched_slovar4\n",
        "            total_unmatched = len(unique_lemmas) - total_matched\n",
        "\n",
        "            # Ensure that the total number of unmatched lemmas is not negative\n",
        "            total_unmatched = max(0, total_unmatched)\n",
        "\n",
        "            # Calculate the percentage of unmatched lemmas\n",
        "            unmatched_percentage = (total_unmatched / len(unique_lemmas)) * 100 if len(unique_lemmas) > 0 else 0\n",
        "\n",
        "            total_unmatched_percentage += unmatched_percentage\n",
        "            total_unmatched_tokens += total_unmatched\n",
        "            total_files += 1\n",
        "\n",
        "    avg_unmatched_percentage = total_unmatched_percentage / total_files if total_files > 0 else 0\n",
        "    avg_unmatched_tokens = total_unmatched_tokens / total_files if total_files > 0 else 0\n",
        "    return avg_unmatched_percentage, avg_unmatched_tokens\n",
        "\n",
        "# Process folders A1, A2, B1, B2 with SMARTool dictionaries\n",
        "print(\"Processing with KELLY dictionaries:\")\n",
        "folders = [\"A1\", \"A2\", \"B1\", \"B2\"]\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(students_path, folder)\n",
        "    avg_unmatched_percentage, avg_unmatched_tokens = process_folder(folder_path, slovar1, slovar2, slovar3, slovar4)\n",
        "    print(f\"Average unmatched lemmas percentage for folder {folder} (SMARTool): {avg_unmatched_percentage:.2f}%\")\n",
        "    print(f\"Average unmatched lemmas count for folder {folder} (SMARTool): {avg_unmatched_tokens:.2f}\")\n",
        "\n",
        "# Process folders A1, A2, B1, B2 with new vocabularies\n",
        "print(\"\\nProcessing with new vocabularies:\")\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join(students_path, folder)\n",
        "    avg_unmatched_percentage, avg_unmatched_tokens = process_folder(folder_path, slovar_nv1, slovar_nv2, slovar_nv3, slovar_nv4)\n",
        "    print(f\"Average unmatched lemmas percentage for folder {folder} (New Vocabularies): {avg_unmatched_percentage:.2f}%\")\n",
        "    print(f\"Average unmatched lemmas count for folder {folder} (New Vocabularies): {avg_unmatched_tokens:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niv04XAj-Bgp",
        "outputId": "2a2557d1-04cd-4fd2-9968-170fca863fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing with KELLY dictionaries:\n",
            "Average unmatched lemmas percentage for folder A1 (SMARTool): 48.07%\n",
            "Average unmatched lemmas count for folder A1 (SMARTool): 19.48\n",
            "Average unmatched lemmas percentage for folder A2 (SMARTool): 47.82%\n",
            "Average unmatched lemmas count for folder A2 (SMARTool): 42.92\n",
            "Average unmatched lemmas percentage for folder B1 (SMARTool): 53.52%\n",
            "Average unmatched lemmas count for folder B1 (SMARTool): 67.73\n",
            "Average unmatched lemmas percentage for folder B2 (SMARTool): 58.75%\n",
            "Average unmatched lemmas count for folder B2 (SMARTool): 98.98\n",
            "\n",
            "Processing with new vocabularies:\n",
            "Average unmatched lemmas percentage for folder A1 (New Vocabularies): 48.82%\n",
            "Average unmatched lemmas count for folder A1 (New Vocabularies): 19.70\n",
            "Average unmatched lemmas percentage for folder A2 (New Vocabularies): 49.49%\n",
            "Average unmatched lemmas count for folder A2 (New Vocabularies): 44.09\n",
            "Average unmatched lemmas percentage for folder B1 (New Vocabularies): 54.81%\n",
            "Average unmatched lemmas count for folder B1 (New Vocabularies): 69.31\n",
            "Average unmatched lemmas percentage for folder B2 (New Vocabularies): 60.21%\n",
            "Average unmatched lemmas count for folder B2 (New Vocabularies): 101.35\n"
          ]
        }
      ]
    }
  ]
}